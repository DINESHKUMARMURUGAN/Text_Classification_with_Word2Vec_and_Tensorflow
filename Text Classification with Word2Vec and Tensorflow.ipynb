{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "edbfce39-fa2a-4616-a8d4-87362749e8f4",
    "_uuid": "e5b7147a607eadc89778d8045cc4ff040036fd71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "a12c2147-d021-41c7-9de3-04e52c70c477",
    "_uuid": "d9e403e9ebb31423e8a8303ec5b645d8c90e92f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7ff2f356-426e-4c21-842c-be30b27e9e25",
    "_uuid": "37014efb49740dd01a4aa52a063347e3de384d00"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2017-10-27 18:10:07--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘nlp.stanford.edu’\n",
      "unzip:  cannot find or open glove.6B.zip, glove.6B.zip.zip or glove.6B.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "135f492c3a1d901ae162763aa99fbfde7ffdaf9b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk as nl\n",
    "train['tokens'] = [nl.word_tokenize(sentences) for sentences in train.text]\n",
    "words = []\n",
    "for item in train.tokens:\n",
    "    words.extend(item)\n",
    "\n",
    "stemmer = nl.stem.lancaster.LancasterStemmer()\n",
    "words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "\n",
    "filtered_words = [word for word in words if word not in nl.corpus.stopwords.words('english')]\n",
    "\n",
    "\n",
    "\n",
    "import gensim\n",
    "# let X be a list of tokenized texts (i.e. list of lists of tokens)\n",
    "model = gensim.models.Word2Vec(filtered_words, size=100)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48447788,  0.37772679,  0.1721192 , -0.25281611, -0.08350382,\n",
       "       -0.26236266, -0.35221589, -0.11461841,  0.01211224,  0.16695961,\n",
       "        0.36798939, -0.24858071, -0.30548489, -0.1226057 , -0.01497782,\n",
       "       -0.42093369,  0.19981885, -0.60778433, -0.25410685,  0.21789254,\n",
       "        0.27064028, -0.01399691,  0.06578006,  0.11984596,  0.27820253,\n",
       "        0.48097903, -0.21241115,  0.2023008 , -0.15852831, -0.06108602,\n",
       "       -0.28014383,  0.23098896,  0.25369716, -0.28983158,  0.22965187,\n",
       "       -0.05795765,  0.34624857, -0.20967057, -0.14075291, -0.29322013,\n",
       "       -0.46175703,  0.04668606, -0.4968957 ,  0.06816328,  0.2058243 ,\n",
       "       -0.06381508, -0.2770367 ,  0.23208925,  0.2076458 ,  0.04258641,\n",
       "        0.0881149 , -0.16849409,  0.20704637,  0.21805969, -0.17064475,\n",
       "        0.37618664,  0.16684383, -0.15153997, -0.37234405, -0.21195473,\n",
       "        0.25754294,  0.15656258,  0.52061534, -0.65176928, -0.25596833,\n",
       "        0.55746633,  0.20862029,  0.06659539,  0.36561462,  0.27070168,\n",
       "        0.0149955 , -0.11663842,  0.13512513,  0.03841446,  0.33151382,\n",
       "        0.05431568,  0.09939136, -0.14233097,  0.55665189, -0.29351795,\n",
       "        0.11168498, -0.18661603, -0.47080952, -0.12944253, -0.35610169,\n",
       "        0.18619096, -0.0687995 , -0.11894911,  0.17796999,  0.07777363,\n",
       "        0.13878179,  0.49077624,  0.38451767, -0.187397  ,  0.31149918,\n",
       "       -0.06084521, -0.28224337, -0.37841001,  0.08481147,  0.05380828], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_uuid": "4efafedbdb4c5e75958c7ba000df517a6e4c82a2"
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "for index,item in train.iterrows():\n",
    "    vec = np.zeros(100)\n",
    "    token_words = [stemmer.stem(word) for word in item['tokens']]\n",
    "    token_words = [word for word in token_words if word not in nl.corpus.stopwords.words('english')]\n",
    "    for w in token_words:\n",
    "        if w in w2v:\n",
    "            vec += w2v[w]\n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm != 0:\n",
    "        vec /= np.linalg.norm(vec)\n",
    "    \n",
    "    \n",
    "    training.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d16c7398eb6df6c692c0eedc81521ac051303e42",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_new = np.array(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "09f8a1f39f9a79f08e00da6e922cc3773d895b92",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(training_new[:,1])\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "train_y = onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "61b9f844a5d6e4dad9a5a60c3a02efd94dfffa11",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = list(training_new[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "38bd2f15a66d7daf662f3d4a77db2c9e8368cf6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 24479  | total loss: \u001b[1m\u001b[32m1.07462\u001b[0m\u001b[0m | time: 8.087s\n",
      "| Adam | epoch: 010 | loss: 1.07462 - acc: 0.4479 -- iter: 19576/19579\n",
      "Training Step: 24480  | total loss: \u001b[1m\u001b[32m1.07736\u001b[0m\u001b[0m | time: 8.090s\n",
      "| Adam | epoch: 010 | loss: 1.07736 - acc: 0.4406 -- iter: 19579/19579\n",
      "--\n",
      "INFO:tensorflow:/Users/dmurugan/mess/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    " \n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(train_x, train_y, n_epoch=10, batch_size=8, show_metric=True)\n",
    "model.save('model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "3c3205186ee0ff70df4c88c864a3ce72332822c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('./input/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "fd69f717119691d89dc46fde0664d592689a2fb2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['tokens'] = [nl.word_tokenize(sentences) for sentences in test.text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "db8315c7e4028445cbbe28ec6754ffe6e325d967",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = []\n",
    "for index,item in test.iterrows():\n",
    "    vec = np.zeros(100)\n",
    "    token_words = [stemmer.stem(word) for word in item['tokens']]\n",
    "    token_words = [word for word in token_words if word not in nl.corpus.stopwords.words('english')]\n",
    "    for w in token_words:\n",
    "        if w in w2v:\n",
    "            vec += w2v[w]\n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm != 0:\n",
    "        vec /= np.linalg.norm(vec)\n",
    "    \n",
    "    \n",
    "    testing.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ffbe0590e82ce0e958aa8f95e2fe9a74d424d88e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.295293</td>\n",
       "      <td>0.312747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.399334</td>\n",
       "      <td>0.274379</td>\n",
       "      <td>0.326287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.388437</td>\n",
       "      <td>0.299305</td>\n",
       "      <td>0.312257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.395750</td>\n",
       "      <td>0.284641</td>\n",
       "      <td>0.319608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.387966</td>\n",
       "      <td>0.306310</td>\n",
       "      <td>0.305724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP       HPL       MWS\n",
       "0  id02310  0.391960  0.295293  0.312747\n",
       "1  id24541  0.399334  0.274379  0.326287\n",
       "2  id00134  0.388437  0.299305  0.312257\n",
       "3  id27757  0.395750  0.284641  0.319608\n",
       "4  id04081  0.387966  0.306310  0.305724"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = list(np.array(testing))\n",
    "predicted = model.predict(X=testing)\n",
    "result_val = pd.DataFrame(predicted)\n",
    "result_val.columns = [\"EAP\",\"HPL\",\"MWS\"]\n",
    "result = pd.DataFrame(columns=['id'])\n",
    "result['id'] = test['id']\n",
    "result['EAP'] = result_val['EAP']\n",
    "result['HPL'] = result_val['HPL']\n",
    "result['MWS'] = result_val['MWS']\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0aadc1c133446e196a7af9c90feec536bc228807",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(\"my_submission_v2.csv\", encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
